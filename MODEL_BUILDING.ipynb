{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "5NJXNVFRbEky"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "ipTelQoybLuz"
   },
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2626 images belonging to 5 classes.\n",
      "Found 1055 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define data generators for training and testing data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values to [0, 1]\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)   # Rescale pixel values to [0, 1]\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'TRAIN_SET_FINAL',  # Path to the training data directory\n",
    "    target_size=(32, 32),  # Resize images to (32, 32)\n",
    "    batch_size=32,  # Number of samples per batch\n",
    "    class_mode='categorical'  # Type of label encoding\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'TEST_SET_FINAL',   # Path to the testing data directory\n",
    "    target_size=(32, 32),  # Resize images to (32, 32)\n",
    "    batch_size=32,  # Number of samples per batch\n",
    "    class_mode='categorical'  # Type of label encoding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "yU8BwCkGbOdf"
   },
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale=(1./255),horizontal_flip=True,shear_range=0.2)\n",
    "test_gen = ImageDataGenerator(rescale=(1./255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MdLd8mEWbRou",
    "outputId": "5d0c3e06-38fb-45ae-83ef-fdfa549d4601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2626 images belonging to 5 classes.\n",
      "Found 1055 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train = train_gen.flow_from_directory('TRAIN_SET_FINAL',\n",
    "target_size=(120, 120),\n",
    "class_mode='categorical',\n",
    "batch_size=8)\n",
    "\n",
    "test = test_gen.flow_from_directory('TEST_SET_FINAL',\n",
    "target_size=(120, 120),\n",
    "class_mode='categorical',\n",
    "batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n",
      "{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n"
     ]
    }
   ],
   "source": [
    "train_class_indices = train_generator.class_indices\n",
    "test_class_indices = test_generator.class_indices\n",
    "\n",
    "print(train_class_indices)\n",
    "print(test_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYVPKdJRfgQg",
    "outputId": "84788b08-a3c9-456c-df61-1134c16ae04d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 606, 1: 445, 2: 621, 3: 475, 4: 479})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter as c\n",
    "c(train.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "3SvOOyPBf9Gl"
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "netwCDDegFnk",
    "outputId": "90f543fb-1107-4f1a-d911-6b4948d17313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122570 (478.79 KB)\n",
      "Trainable params: 122570 (478.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzVbyXNbgLA0",
    "outputId": "5b27c436-d46b-4d76-a7b0-aa24c334d4ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 91s 57ms/step - loss: 0.8138 - accuracy: 0.7143 - val_loss: 0.8682 - val_accuracy: 0.6988\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 78s 50ms/step - loss: 0.7633 - accuracy: 0.7334 - val_loss: 0.8761 - val_accuracy: 0.6972\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 79s 51ms/step - loss: 0.7155 - accuracy: 0.7481 - val_loss: 0.8722 - val_accuracy: 0.7028\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 85s 54ms/step - loss: 0.6727 - accuracy: 0.7630 - val_loss: 0.8611 - val_accuracy: 0.7083\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 78s 50ms/step - loss: 0.6311 - accuracy: 0.7762 - val_loss: 0.8877 - val_accuracy: 0.7049\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 80s 51ms/step - loss: 0.5938 - accuracy: 0.7898 - val_loss: 0.8750 - val_accuracy: 0.7168\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 82s 53ms/step - loss: 0.5571 - accuracy: 0.8038 - val_loss: 0.8918 - val_accuracy: 0.7118\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 79s 50ms/step - loss: 0.5270 - accuracy: 0.8135 - val_loss: 0.9306 - val_accuracy: 0.7100\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 80s 51ms/step - loss: 0.4925 - accuracy: 0.8257 - val_loss: 0.9306 - val_accuracy: 0.7125\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 84s 54ms/step - loss: 0.4649 - accuracy: 0.8333 - val_loss: 0.9398 - val_accuracy: 0.7164\n"
     ]
    }
   ],
   "source": [
    "#Compiling the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "#Fitting the model\n",
    "history = model.fit(train_images, train_labels, epochs=10,\n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cZ9v2BFqcA8",
    "outputId": "03487ab5-289a-4e43-dcbd-fb6cb97d4048"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               131200    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 188,165\n",
      "Trainable params: 188,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a Conv2D layer with 32 filters, each filter size is 3x3, and ReLU activation\n",
    "# Input shape is (32, 32, 3)\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "\n",
    "# Add a MaxPooling2D layer with pool size 2x2\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add another Conv2D layer with 64 filters, each filter size is 3x3, and ReLU activation\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add another MaxPooling2D layer with pool size 2x2\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add another Conv2D layer with 64 filters, each filter size is 3x3, and ReLU activation\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Flatten the output of the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a Dense layer with 128 units and ReLU activation\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Add a Dense layer with 5 units (for the output classes) and softmax activation\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "83/83 [==============================] - 36s 386ms/step - loss: 0.3446 - accuracy: 0.8778 - val_loss: 0.0609 - val_accuracy: 0.9659\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 6s 72ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1125 - val_accuracy: 0.9536\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 3.9532e-04 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9517\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 1.8006e-04 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9431\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 8.8022e-05 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9441\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 5s 66ms/step - loss: 5.0384e-05 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9422\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 5s 66ms/step - loss: 3.5616e-05 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9450\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 6s 71ms/step - loss: 2.5483e-05 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9431\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 5s 66ms/step - loss: 1.9303e-05 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9422\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 1.5508e-05 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9403\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 5s 57ms/step - loss: 1.2534e-05 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9422\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 5s 64ms/step - loss: 1.0115e-05 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9422\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 5s 61ms/step - loss: 8.8371e-06 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9422\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 7.7299e-06 - accuracy: 1.0000 - val_loss: 0.1588 - val_accuracy: 0.9431\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 6s 70ms/step - loss: 6.2891e-06 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9422\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 6s 68ms/step - loss: 5.5448e-06 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9422\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 6s 68ms/step - loss: 4.7369e-06 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9403\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 4.1956e-06 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9403\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 6s 67ms/step - loss: 3.7353e-06 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9422\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 6s 69ms/step - loss: 3.3928e-06 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9422\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,  # Training data generator\n",
    "    epochs=20,  # Number of epochs\n",
    "    validation_data=test_generator,  # Testing data generator\n",
    "    verbose=1  # Print training progress\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "QCOy-aOjd9-l"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "#Prediciting our results\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "# model=load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "4p4DX45IeG_i",
    "outputId": "6102531b-aaf5-448d-f668-451642fe0e73"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = image.load_img('TEST_SET_FINAL/APPLES/0_100.jpg',target_size=(32,32))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iy1mOmTMeYWP",
    "outputId": "e4c07cbe-89c2-4241-bdea-c018fa8b1e1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [254., 255., 255.],\n",
       "        [254., 255., 253.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 254., 255.],\n",
       "        [255., 252., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [254., 255., 255.],\n",
       "        [251., 255., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255., 254., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [254., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [254., 255., 255.],\n",
       "        [254., 255., 253.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 254., 255.],\n",
       "        [255., 255., 255.]],\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 255., 255.]]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = image.img_to_array(img)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jc7tJUE4ekTO",
    "outputId": "e409be76-4be3-4ac2-a4df-7b636513161b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [254., 255., 255.],\n",
       "         [254., 255., 253.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 254., 255.],\n",
       "         [255., 252., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [254., 255., 255.],\n",
       "         [251., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255., 254., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [254., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [254., 255., 255.],\n",
       "         [254., 255., 253.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 254., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]]]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.expand_dims(img,axis=0)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTa4n2AnhHrG",
    "outputId": "961b9b50-d044-408e-c110-b0b01d0d9e6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_probabilities = model.predict(img)\n",
    "pred_classes = np.argmax(pred_probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CZ9CXOgnAUs9",
    "outputId": "36ab287d-b44c-4db6-c005-5a161102ac1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's an Apple\n",
      "Predicted class index: 0\n"
     ]
    }
   ],
   "source": [
    "# Map class indices to fruit names\n",
    "fruit_mapping = {'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n",
    "\n",
    "if pred_classes[0] == 0:\n",
    "    print(\"It's an Apple\")\n",
    "elif pred_classes[0] == 1:\n",
    "    print(\"It's a Banana\")\n",
    "elif pred_classes[0] == 2:\n",
    "    print(\"It's a Pineapple\")\n",
    "elif pred_classes[0] == 3:\n",
    "    print(\"It's a Watermelon\")\n",
    "else:\n",
    "    print(\"It's an Orange\")\n",
    "\n",
    "print(\"Predicted class index:\", pred_classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "hWtRClW_jz8r"
   },
   "outputs": [],
   "source": [
    "#Saving our model\n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
